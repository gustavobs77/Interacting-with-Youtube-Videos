{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedc88ed-e72b-4071-a552-5348c0144cde",
   "metadata": {},
   "source": [
    "# Método 1 - Aprendizado ( Method 1- learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590c6d4-a825-48ce-9a22-560ac76c7982",
   "metadata": {},
   "source": [
    "## installing tools and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101ddba-2528-473b-873c-9c439b7d981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community langchain-huggingface langchain_ollama\n",
    "#!pip install youtube-transcript-api\n",
    "#!pip install pytube\n",
    "#!pip install --upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c294c6c-71d1-4a7d-8061-c11700644665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import getpass\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb61a6c-d03d-48dc-84e5-091a78026386",
   "metadata": {},
   "source": [
    "## Getting the video informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6d18fc9c-fcf3-465b-bafb-a5d011e65e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=PeMlggyqz0Y&t=6s\", language = [\"pt\", \"pt-BR\",\"en\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "02377d06-dd77-44ff-84df-cd128bf547f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = video_loader.load()\n",
    "#infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "81bcd390-cac4-4a51-8f15-c435a9b4e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = infos[0].page_content\n",
    "#transcricao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "95314f87-7094-4321-b323-6d9ed34fd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = f\"\"\"\n",
    "Informações do vídeo:\n",
    "Título: {infos[0].metadata.get('title', 'unailable')}\n",
    "Autor: {infos[0].metadata.get('author', 'unailable')}\n",
    "Data: {infos[0].metadata.get('publish_date', 'unailable')[:10]}\n",
    "URL: https://www.youtube.com/watch?v={infos[0].metadata.get('source', 'unailable')}\n",
    "\n",
    "Transcrição: {infos[0].page_content}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8fc4abc9-e7db-4a0f-8fb8-2a1c1ab6e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a txt file with the video infos\n",
    "with io.open(\"transcription.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "    for doc in infos:\n",
    "        f.write(video_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20accd40-1bc5-4389-a830-1c850db8ba9e",
   "metadata": {},
   "source": [
    "## Load models - LLM - HuggingFaceHub or Ollama (phi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d8c51d1c-54d8-4dd2-9fc6-624dec8673f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# If you choose a Huggingface template, the access token will be required\n",
    "# If you chose the Ollama phi3 model, you must download ollama on : https://ollama.com/download. After that, open the command prompt and type :ollama pull phi3\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c8af6-5b80-4ae3-aeb0-c9eca8f0464e",
   "metadata": {},
   "source": [
    "## Defining the model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "88baace9-41fa-45e1-8d9f-46bf073b9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_hf_hub(model = \"meta-llama/Meta-Llama-3-8B-Instruct\", temperature = 0.1):\n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id = model, \n",
    "        model_kwargs={\n",
    "        \"temperature\":temperature, \n",
    "        \"return_full_text\":False, \n",
    "        \"max_new_tokens\":1024\n",
    "                     }\n",
    "                        )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d8e28e93-482c-4b48-adcd-e8f2935d2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ollama(model = \"phi3\", temperature = 0.1):\n",
    "    llm = ChatOllama(model = model,temperature = temperature)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "146713f0-e532-4449-b70f-46642c21f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = \"ollama\" #[hf_hub, \"ollama\"]\n",
    "if model_class == \"hf_hub\":\n",
    "    llm = model_hf_hub()\n",
    "else:\n",
    "    llm = model_ollama()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17150252-5a1f-4fe0-924c-7c85096aaaca",
   "metadata": {},
   "source": [
    "## Creating the Prompt and the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0bb5e15c-19e8-42ea-b4b5-2972107fefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"você é um assistente prestativo e deve responder a uma consulta baseada em uma transcrição de um vídeo\"\n",
    "inputs = \"Query: {query} \\n Transcription: {transcription}\"\n",
    "if model_class.startswith(\"hf\"):\n",
    "    user_prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "else:\n",
    "    user_prompt = \"{}\".format(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c9aff282-b71b-441d-9896-8ef59878b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\",system_prompt), (\"user\", user_prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "61db1fbc-67b6-47ce-b4a4-c60fd25aaa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65014d27-e0f8-4a9f-a1f0-b19a0af1ced0",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8d0bbb5c-2f94-4a12-8983-1972e4ba46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary information from the video transcription is that it provides an overview of what Machine Learning (ML) entails, its history dating back to Arthur Samuel's work at IBM in 1959 on checkers-playing AI. The explanation covers how ML algorithms learn tasks without explicit programming by feeding data into them and iteratively improving outcomes based on experience—akin to organic learning processes.\n",
      "\n",
      "The video also touches upon the two fundamental jobs of predictive models: classification (determining if a car is present or cancer diagnosis) and prediction about future events, such as stock prices movements or suggesting YouTube videos for viewing next. The process begins with data acquisition and cleanup to ensure quality input that represents the problem well since \"garbage in, garbage out.\"\n",
      "\n",
      "Feature engineering transforms raw data into features representing the underlying issue better suited for ML algorithms like linear regression, logistic regression, decision trees or convolutional neural networks (CNN), which are particularly adept at handling complex inputs such as images and natural language. The video emphasizes that choosing an appropriate algorithm is crucial to building a successful model.\n",
      "\n",
      "The training phase involves feeding the cleaned data into algorithms like linear regression—which uses statistical methods, or decision trees—that assign different weights to features in the dataset for making predictions. For classification problems, accuracy might be used as an error function; mean absolute error could serve this purpose for regression tasks. Python is highlighted as a popular language among data scientists due to its extensive libraries and frameworks that facilitate ML processes but acknowledges R and Julia's growing use in the field too.\n",
      "\n",
      "The video concludes by explaining how machine learning models, once trained (a file containing learned patterns), can be deployed on actual devices or cloud platforms for real-world applications—demonstrating its practical utility across various industries today. The invitation to subscribe and leave comments suggests that the channel offers more content related to ML in brief formats like this one.\n"
     ]
    }
   ],
   "source": [
    "res = chain.invoke({\"transcription\":transcricao, \"query\":\"qual a principal informação do vídeo ?\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f26773-3efd-40be-8377-9de2be4c2d30",
   "metadata": {},
   "source": [
    "# Method 2- Unified Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090ad00-c566-4c18-b518-24b05f4b88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import getpass\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "74283b70-14e8-4c13-a072-87f6b7f78037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_chain(model_class):\n",
    "  system_prompt = \"Você é um assistente virtual prestativo e deve responder a uma consulta com base na transcrição de um vídeo, que será fornecida abaixo.\"\n",
    "\n",
    "  inputs = \"Consulta: {consulta} \\n Transcrição: {transcricao}\"\n",
    "\n",
    "  if model_class.startswith(\"hf\"):\n",
    "      user_prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".format(inputs)\n",
    "  else:\n",
    "      user_prompt = \"{}\".format(inputs)\n",
    "\n",
    "  prompt_template = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", system_prompt),\n",
    "      (\"user\", user_prompt)\n",
    "  ])\n",
    "\n",
    "  ### Carregamento da LLM\n",
    "  if model_class == \"hf_hub\":\n",
    "      llm = model_hf_hub()\n",
    "  \n",
    "  else:\n",
    "      llm = model_ollama()\n",
    "\n",
    "  chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "  return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fe15f2e2-467b-40bb-b8b4-4cae865cb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(url_video, language=\"pt\", translation=None):\n",
    "\n",
    "  video_loader = YoutubeLoader.from_youtube_url(\n",
    "      url_video,\n",
    "      language=language,\n",
    "      translation=translation,\n",
    "  )\n",
    "\n",
    "  infos = video_loader.load()[0]\n",
    "  metadata = infos.metadata\n",
    "  transcript = infos.page_content\n",
    "\n",
    "  return transcript, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "170334b1-e132-4812-934c-02b27c57202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript, metadata = get_video_info(\"https://www.youtube.com/watch?v=II28i__Tf3M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "98aadfe8-d3c5-4bfe-9650-791ed0ea5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata, transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c5fb52c8-6dbb-4c9a-ad86-b89aced41aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_video(url, query=\"resuma\", model_class=\"hf_hub\", language=\"pt\", translation=None):\n",
    "\n",
    "  try:\n",
    "    transcript, metadata = get_video_info(url, language, translation)\n",
    "\n",
    "    chain = llm_chain(model_class)\n",
    "\n",
    "    res = chain.invoke({\"transcricao\": transcript, \"consulta\": query})\n",
    "    print(res)\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"Erro ao carregar transcrição\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bec216-c421-4f49-bf78-2d7879bfdf28",
   "metadata": {},
   "source": [
    "## Inserting the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9483dc0d-d956-42d0-81cb-c144d1eef2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_video = \"https://www.youtube.com/watch?v=PeMlggyqz0Y&t=6s\" # @param {type:\"string\"}\n",
    "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
    "model_class = \"ollama\" # @param [\"hf_hub\", \"ollama\"]\n",
    "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e603895c-bf58-481e-ad7e-ff0ff872c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Summary: Machine learning enables computers to learn tasks without explicit programming by feeding data into algorithms. Arthur Samuel coined \"artificial intelligence\" at IBM, leading to AI that can play checkers decades later. Predictive models are integral to daily products for classifying (e.g., car detection) and forecasting outcomes (e.g., stock prices). The process begins with data acquisition and cleanup—quality is key as \"garbage in, garbage out.\" Data scientists transform raw data into features via feature engineering that better represent the problem at hand.\n",
      "\n",
      "Data sets are divided into training and testing subsets; models learn from the former while validation accuracy or error on test data ensures model reliability. Choosing an appropriate algorithm—from simple regression to complex neural networks capable of automatic feature creation, especially for image or natural language processing—is crucial next. Algorithms improve by minimizing a chosen error function through comparison with actual outcomes in classification tasks (e.g., identifying cats vs. dogs) and predicting continuous values like future bread prices using regression models.\n",
      "\n",
      "Python is the preferred programming language for data scientists, though R and Julia are also used alongside various frameworks to simplify machine learning workflows. The end product of this process is a model file that inputs new data in its trained format and outputs predictions aimed at minimizing error based on prior optimization efforts. These models can be deployed locally or remotely for real-world applications, exemplifying the practical impact of machine learning summarized succinctly herein.\n"
     ]
    }
   ],
   "source": [
    "interpret_video(url_video, query_user, model_class, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4bd20-5614-4f20-8d15-497401b2f4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
